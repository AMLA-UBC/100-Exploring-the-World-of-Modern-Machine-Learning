{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AMLA-UBC/100-Exploring-the-World-of-Modern-Machine-Learning/blob/main/Multiclass_Classification_Exercise.ipynb)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this exercise, we will guide you through the process of creating, compiling, and training a multi-class classification model using the Cifar10 dataset. Then you are asked to create your own model to improve the simple CNN to achieve a higher accuracy in an efficient manner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8rr74liK4g_"
      },
      "source": [
        "# Install and Import Required Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cEoFqqyK2W6"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_5kNqqeK7ti"
      },
      "source": [
        "# Load the Cifar10 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDxapXPhLno0"
      },
      "source": [
        "The CIFAR-10 dataset contains 60,000 32x32 colored images in 10 classes, with 6,000 images per class. The 10 classes are airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnoCv4j4KeKD"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Pre-process the data\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B7Xq2d3LCUa"
      },
      "source": [
        "# Task 1 - Train and Evaluate this Feedforward Neural Network\n",
        "\n",
        "One of the most fundamental types of neural networks is the feedforward neural network. These networks consist of three layers: the input layer, one or more hidden layers, and the output layer.\n",
        "\n",
        "The beauty of feedforward neural networks is that they can be trained using data, and they form the foundation for a wide range of applications such as computer vision and natural language processing. They are the backbone of many neural networks and are capable of solving real-world problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESvbNas1k2iE"
      },
      "source": [
        "\n",
        "This code is building and training a model with TensorFlow 2. The model is a simple neural network with two layers. The first layer is a flatten layer, which takes the input data and flattens it into a 1-dimensional array. The second layer is a dense layer with 128 neurons and a ReLU activation function. The third layer is a dense layer with 10 neurons and a softmax activation function.\n",
        "\n",
        "The code then compiles the model by specifying an optimizer (Adam), a loss function (sparse categorical crossentropy), and a metric (accuracy). The optimizer is responsible for adjusting the weights of the model to minimize the loss. The loss function calculates the difference between the predicted output and the actual output. The metric is used to measure the accuracy of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmZGXFfiLM4C"
      },
      "source": [
        "Ensure that the code is completed correctly so that the model can compile and learn from the dataset without any issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EloniJM8LJpT"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(..., ..., ...)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = ...\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r27GJtoBbxSs"
      },
      "source": [
        "If you find yourself stuck for more than 10 minutes, refer to the example solution at the bottom of the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWgJOjWucIOa",
        "outputId": "11b18dad-e931-4e46-daf4-49fdd3bd813e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 1.9001 - accuracy: 0.3174\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.7513 - accuracy: 0.3731\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.6960 - accuracy: 0.3947\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.6668 - accuracy: 0.4041\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.6402 - accuracy: 0.4134\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.6224 - accuracy: 0.4181\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.6030 - accuracy: 0.4290\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.5948 - accuracy: 0.4305\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.5805 - accuracy: 0.4364\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.5724 - accuracy: 0.4413\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.6758 - accuracy: 0.4108\n",
            "Test accuracy: 0.4108000099658966\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Solution in Node.js\n",
        "\"\"\"\n",
        "const tf = require('@tensorflow/tfjs-node');\n",
        "\n",
        "// Load the dataset\n",
        "const cifar10 = require('@tensorflow/tfjs-data/cifar10');\n",
        "const { xTrain, yTrain, xTest, yTest } = cifar10.getData(1);\n",
        "\n",
        "// Pre-process the data\n",
        "const xTrainNorm = xTrain.div(tf.scalar(255));\n",
        "const xTestNorm = xTest.div(tf.scalar(255));\n",
        "\n",
        "// Build the model\n",
        "const model = tf.sequential();\n",
        "model.add(tf.layers.flatten({ inputShape: [32, 32, 3] }));\n",
        "model.add(tf.layers.dense({ units: 128, activation: 'relu' }));\n",
        "model.add(tf.layers.dense({ units: 10, activation: 'softmax' }));\n",
        "\n",
        "// Compile the model\n",
        "model.compile({\n",
        "  optimizer: tf.train.adam(),\n",
        "  loss: 'sparseCategoricalCrossentropy',\n",
        "  metrics: ['accuracy'],\n",
        "});\n",
        "\n",
        "// Train the model\n",
        "model.fit(xTrainNorm, yTrain, {\n",
        "  epochs: 10,\n",
        "  callbacks: {\n",
        "    onEpochEnd: async (epoch, log) => {\n",
        "      console.log(`Epoch ${epoch}: loss = ${log.loss}, accuracy = ${log.acc}`);\n",
        "    }\n",
        "  }\n",
        "});\n",
        "\n",
        "// Evaluate the model\n",
        "const result = model.evaluate(xTestNorm, yTest);\n",
        "const testAcc = result[1];\n",
        "\n",
        "console.log('Test accuracy:', testAcc);\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIIvId7HjBzZ"
      },
      "source": [
        "# Task 2 - Complete this Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfMXuA9VjPhZ"
      },
      "source": [
        "This code is creating a Convolutional Neural Network (CNN) with TensorFlow 2. A CNN is a type of deep learning algorithm that is used to analyze visual imagery and is made up of a series of layers. The first line of code creates the model, which is the basic structure of the network. The next lines add different layers to the model. The Conv2D layer creates a convolutional layer that takes in an image of size 32x32x3 as input and applies a set of filters to it. The MaxPooling2D layer then reduces the size of the image by taking the maximum value of the pixels in a given area. The Flatten layer then takes the output of the MaxPooling2D layer and flattens it into a single long vector. The Dense layer then takes the flattened vector as input and applies a set of weights to it. Finally, the last Dense layer has 10 nodes, which is the number of classes we are predicting, and applies a softmax activation function to the output. The last line of code compiles the model, which means it sets up the model to be trained by specifying the optimizer, loss function, and metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Tn74EWinLDQ"
      },
      "source": [
        "Refer to the explanation above for hints and read the comments below to find out what to add."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxEG2rYSjpGV"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "\n",
        "# Add the input shape of our preprocessed data\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(...)))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "\n",
        "\n",
        "# Add the output layer\n",
        "model.add(...)\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4NUnEbxkDJ6"
      },
      "source": [
        "If you find yourself stuck for more than 10 minutes, refer to the example solution at the bottom of the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhL14x2tkD3v",
        "outputId": "02621b99-b79a-4132-f916-01a5628c2649"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 13s 3ms/step - loss: 1.4511 - accuracy: 0.4833\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1624 - accuracy: 0.5912\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0375 - accuracy: 0.6393\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9429 - accuracy: 0.6700\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8645 - accuracy: 0.6964\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8028 - accuracy: 0.7173\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7440 - accuracy: 0.7395\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6870 - accuracy: 0.7600\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6319 - accuracy: 0.7791\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5789 - accuracy: 0.7971\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.1589 - accuracy: 0.6391\n",
            "Test accuracy: 0.6391000151634216\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Solution in Node.js\n",
        "\"\"\"\n",
        "const tf = require('@tensorflow/tfjs-node');\n",
        "\n",
        "// Build the model\n",
        "const model = tf.sequential();\n",
        "model.add(tf.layers.conv2d({ inputShape: [32, 32, 3], kernelSize: 3, filters: 32, activation: 'relu' }));\n",
        "model.add(tf.layers.maxPooling2d({ poolSize: [2, 2] }));\n",
        "model.add(tf.layers.flatten());\n",
        "model.add(tf.layers.dense({ units: 128, activation: 'relu' }));\n",
        "model.add(tf.layers.dense({ units: 10, activation: 'softmax' }));\n",
        "\n",
        "// Compile the model\n",
        "const optimizer = tf.train.adam();\n",
        "model.compile({\n",
        "  optimizer: optimizer,\n",
        "  loss: 'sparseCategoricalCrossentropy',\n",
        "  metrics: ['accuracy']\n",
        "});\n",
        "\n",
        "// Train the model\n",
        "model.fit(x_train, y_train, {\n",
        "  epochs: 10,\n",
        "  callbacks: {\n",
        "    onEpochEnd: async (epoch, log) => {\n",
        "      console.log(`Epoch ${epoch}: loss = ${log.loss}, accuracy = ${log.acc}`);\n",
        "    }\n",
        "  }\n",
        "});\n",
        "\n",
        "// Evaluate the model\n",
        "const testResult = model.evaluate(x_test, y_test);\n",
        "const testAccuracy = testResult[1];\n",
        "\n",
        "console.log('Test accuracy:', testAccuracy);\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dF9Q14LeFiv"
      },
      "source": [
        "# Task 3 - Build and Train Your Own Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7rNdxH0eK25"
      },
      "source": [
        "If you are able to train a model that achieves a higher accuracy in roughly the same time, you can request to showcase your project in one of our in-person training sessions or on our GitHub repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hI0xWv4ogm0Q"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "...\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "...\n",
        "\n",
        "\n",
        "# Train the model\n",
        "...\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "...\n",
        "\n",
        "\n",
        "# Save the model\n",
        "...\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
