{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AMLA-UBC/100-Exploring-the-World-of-Modern-Machine-Learning/blob/main/Oneshot_Diffusion_Model_Finetuning_Tutorial.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqzfTcUIvV2v"
      },
      "source": [
        "## DreamArtist: Controllable One-Shot Text-to-Image Generation via Contrastive Prompt-Tuning\n",
        "\n",
        "DreamArtist offers a solution to the limitations of text-to-image generation models, which struggle with synthesizing diverse and high-quality images based on new concepts. DreamArtist uses a contrastive prompt-tuning learning method, which introduces both positive and negative embeddings as pseudo-words and trains them jointly. The positive embedding focuses on learning the characteristics of the reference image, while the negative embedding introspects in a self-supervised manner to correct any mistakes or inadequacies from the positive embedding. This results in the model learning not just what is correct, but also what to avoid. The DreamArtist has been tested and shown to generate high-quality images that also possess form, content, and context, and the pseudo-words have similar properties as true words in generating images.\n",
        "\n",
        "<br>\n",
        "\n",
        "Read more about DreamArtist [here](https://arxiv.org/abs/2211.11337).\n",
        "\n",
        "<br>\n",
        "\n",
        "If you are running on Gradient, use the [Gradient version](https://raw.githubusercontent.com/AMLA-UBC/100-Exploring-the-World-of-Modern-Machine-Learning/main/assets/sd_webui_gradient.txt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaTMyPbGunb0"
      },
      "outputs": [],
      "source": [
        "!pip install -q https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.16/xformers-0.0.16+814314d.d20230118-cp38-cp38-linux_x86_64.whl\n",
        "!pip install -q --pre triton\n",
        "!pip install -q --upgrade fastapi==0.90\n",
        "\n",
        "!git clone -b v1.6 https://github.com/camenduru/stable-diffusion-webui\n",
        "!wget https://raw.githubusercontent.com/camenduru/stable-diffusion-webui-scripts/main/run_n_times.py -O /content/stable-diffusion-webui/scripts/run_n_times.py\n",
        "!git clone https://github.com/yfszzx/stable-diffusion-webui-images-browser /content/stable-diffusion-webui/extensions/stable-diffusion-webui-images-browser\n",
        "!git clone https://github.com/camenduru/stable-diffusion-webui-huggingface /content/stable-diffusion-webui/extensions/stable-diffusion-webui-huggingface\n",
        "!git clone https://github.com/7eu7d7/DreamArtist-sd-webui-extension.git /content/stable-diffusion-webui/extensions/DreamArtist\n",
        "%cd /content/stable-diffusion-webui\n",
        "\n",
        "!wget https://huggingface.co/ckpt/anything-v4.0/resolve/main/anything-v4.0-pruned.ckpt -O /content/stable-diffusion-webui/models/Stable-diffusion/anything-v4.0-pruned.ckpt\n",
        "!wget https://huggingface.co/ckpt/anything-v4.0/resolve/main/anything-v4.5-pruned.ckpt -O /content/stable-diffusion-webui/models/Stable-diffusion/anything-v4.5-pruned.ckpt\n",
        "!wget https://huggingface.co/Lykon/DreamShaper/resolve/main/Dreamshaper_3.32_baked_vae_clip_fix.ckpt -O /content/stable-diffusion-webui/models/Stable-diffusion/Dreamshaper_3.32_baked_vae_clip_fix.ckpt\n",
        "!wget https://huggingface.co/claudfuen/photorealistic-fuen-v1/resolve/main/model.ckpt -O /content/stable-diffusion-webui/models/Stable-diffusion/photorealistic-fuen-v1.ckpt\n",
        "!wget https://huggingface.co/FredZhang7/paint-journey-v2/resolve/main/paint_journey_v2.ckpt -O /content/stable-diffusion-webui/models/Stable-diffusion/paint_journey_v2.ckpt\n",
        "!wget https://huggingface.co/FredZhang7/paint-journey-v2/resolve/main/paint_journey_v2.vae.pt -O /content/stable-diffusion-webui/models/Stable-diffusion/paint_journey_v2.vae.pt\n",
        "!wget https://huggingface.co/ckpt/anything-v4.0/resolve/main/anything-v4.0.vae.pt -O /content/stable-diffusion-webui/models/Stable-diffusion/anything-v4.0-pruned.vae.pt\n",
        "\n",
        "!sed -i -e '''/prepare_environment()/a\\    os.system\\(f\\\"\"\"sed -i -e ''\\\"s/dict()))/dict())).cuda()/g\\\"'' /content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\"\"\")''' /content/stable-diffusion-webui/launch.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU7wN1SlB7_3"
      },
      "source": [
        "## Basic Training\n",
        "\n",
        "[Source of information](https://github.com/7eu7d7/DreamArtist-stable-diffusion)\n",
        "\n",
        "First create the positive and negative embeddings in DreamArtist Create Embedding Tab.\n",
        "![](https://github.com/7eu7d7/DreamArtist-sd-webui-extension/raw/master/imgs/create.jpg)\n",
        "\n",
        "After that, the `names` of the positive and negative embedding (`{name}` and `{name}-neg`) should be filled into the `txt2img` tab with some common descriptions. This will ensure a correct preview image. Here's an example with `{name}`=`test1`.\n",
        "\n",
        "![](https://github.com/7eu7d7/DreamArtist-sd-webui-extension/raw/master/imgs/preview.png)\n",
        "\n",
        "Then, select positive embedding and set the parameters and image folder path in the `DreamArtist Train` tab to start training. The corresponding negative embedding is loaded automatically. If your VRAM is low or you want save time, you can uncheck the `reconstruction`.\n",
        "\n",
        "*better to train without filewords*\n",
        "\n",
        "![](https://github.com/7eu7d7/DreamArtist-sd-webui-extension/raw/master/imgs/train.jpg)\n",
        "\n",
        "Remember to check the option below, otherwise the preview is wrong.\n",
        "\n",
        "![](https://github.com/7eu7d7/DreamArtist-sd-webui-extension/raw/master/imgs/fromtxt.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "## Attention Mask\n",
        "Attention Mask can strengthen or weaken the learning intensity of some local areas. \n",
        "Attention Mask is a grayscale image whose grayscale values are related to the learning intensity show in the following table.\n",
        "\n",
        "| grayscale | 0% | 25% | 50%  | 75%  | 100% |\n",
        "|-----------|----|-----|------|------|------|\n",
        "| intensity | 0% | 50% | 100% | 300% | 500% |\n",
        "\n",
        "The Attention Mask is in the same folder as the training image and its name is the name of the training image + \"_att\".\n",
        "You can choose whether to enable Attention Mask for training.\n",
        "\n",
        "![](https://github.com/7eu7d7/DreamArtist-sd-webui-extension/raw/master/imgs/att_map.jpg)\n",
        "\n",
        "Since there is a self-attention operation in VAE, it may change the distribution of features. \n",
        "In the ***Process Att-Map*** tab, it can superimpose the attention map of self-attention on the original Att-Map.\n",
        "\n",
        "<br>\n",
        "\n",
        "## Dynamic CFG\n",
        "Dynamic CFG can improve the performance, especially when the data set is large (>20). \n",
        "For example, linearly from 1.5 to 3.0 (1.5-3.0), or with a 0-π/2 cycle of cosine (1.5-3.0:cos), or with a -π/2-0 cycle of cosine (1.5-3.0:cos2).\n",
        "Or you can also customize non-linear functions, such as 2.5-3.5:torch.sqrt(rate), where rate is a variable from 0-1.\n",
        "\n",
        "<br>\n",
        "\n",
        "## Inference\n",
        "Fill the trained positive and negative embedding into txt2img to generate with DreamArtist prompt.\n",
        "\n",
        "![](https://github.com/7eu7d7/DreamArtist-sd-webui-extension/raw/master/imgs/gen.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnA3KHNmPgoy"
      },
      "source": [
        "## Launch Camenduru (HuggingFace Automatic1111) WebUI with DreamArtist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-xBUmK0zCHs"
      },
      "outputs": [],
      "source": [
        "!python launch.py --share --xformers --enable-insecure-extension-access"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb2ULqHozP7M"
      },
      "source": [
        "## Add More Diffusion Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGnd8kO4LXm0"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"nitrosocke/spider-verse-diffusion\" #@param [\"nitrosocke/spider-verse-diffusion\", \"nitrosocke/Nitro-Diffusion\", \"nitrosocke/Ghibli-Diffusion\", \"dallinmackay/Van-Gogh-diffusion\", \"coreco/seek.art_MEGA\", \"Aybeeceedee/knollingcase\", \"Fictiverse/Stable_Diffusion_VoxelArt_Model\", \"webui/stable-diffusion-2-1\"] {allow-input: true}\n",
        "URL_MAP = {\n",
        "  \"nitrosocke/spider-verse-diffusion\": \"https://huggingface.co/nitrosocke/spider-verse-diffusion/resolve/main/spiderverse-v1-pruned.ckpt\",\n",
        "  \"nitrosocke/Nitro-Diffusion\": \"https://huggingface.co/nitrosocke/Nitro-Diffusion/resolve/main/nitroDiffusion-v1.ckpt\",\n",
        "  \"nitrosocke/Ghibli-Diffusion\": \"https://huggingface.co/nitrosocke/Ghibli-Diffusion/resolve/main/ghibli-diffusion-v1.ckpt\",\n",
        "  \"dallinmackay/Van-Gogh-diffusion\": \"https://huggingface.co/dallinmackay/Van-Gogh-diffusion/resolve/main/Van-Gogh-Style-lvngvncnt-v2.ckpt\",\n",
        "  \"coreco/seek.art_MEGA\": \"https://huggingface.co/coreco/seek.art_MEGA/resolve/main/seek_art_mega_v1.ckpt\",\n",
        "  \"Aybeeceedee/knollingcase\": \"https://huggingface.co/Aybeeceedee/knollingcase/resolve/main/knollingcase.ckpt\",\n",
        "  \"Fictiverse/Stable_Diffusion_VoxelArt_Model\": \"https://huggingface.co/Fictiverse/Stable_Diffusion_VoxelArt_Model/resolve/main/VoxelArt_v1.ckpt\",\n",
        "  \"webui/stable-diffusion-2-1\": \"https://huggingface.co/webui/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors\"\n",
        "}\n",
        "\n",
        "checkpoint_name = model_checkpoint.split(\"/\")[-1]\n",
        "checkpoint_url = URL_MAP[model_checkpoint]\n",
        "\n",
        "!wget {checkpoint_url} -O /content/stable-diffusion-webui/models/Stable-diffusion/{checkpoint_name}.ckpt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "29f8691f7daccaf63a65f53d7f0e85c97c2d3b005ead1371b5c323153e3b3496"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
